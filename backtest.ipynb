{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af961691",
   "metadata": {},
   "source": [
    "# Dataframe Columns\n",
    "\n",
    "Understanding the dataframe columns:\n",
    "- `ts_recv`: time our client received the message in UTC\n",
    "- `ts_event`: exchange event timestamp of when the trade acc happened\n",
    "- `rtype`: message type code\n",
    "- `publisher_id`: exchange ID\n",
    "- `instrument_id`: symbol of the product\n",
    "- `action`: update action\n",
    "    - `A`: add\n",
    "    - `M`: modify\n",
    "    - `D`: delete\n",
    "    - `T`: trade\n",
    "- `side`: which side the update refers to B for buy, A for ask\n",
    "- `depth`: book level for this single update (0 for top of book, 1 for next level, ...) \n",
    "- `price`: price in update\n",
    "- `size`: number of shares in update\n",
    "- `flags`: special conditions\n",
    "- `ts_in_delta`: time since the previous message\n",
    "- `sequence`: monotonic sequence number for ordering\n",
    "\n",
    "There are columns labled `bid_px_00/ask_px_00` which gives all top-10 levels simultaneously from 00 to 09. 00 is the best bid/ask. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5707464",
   "metadata": {},
   "source": [
    "# Preprocessing Inputs\n",
    "- use `publisher_id` as venue key and the fields `ask_px_00` and `ask_sz_00` as the venues best asks and displayed size (side=ask, depth=0)\n",
    "\n",
    "- for every unique `ts_event` keep only the first message per `publisher_id` that gives one level-1 snapshots per vanue per timestmap\n",
    "    - feed those snapshots order by `ts_event` into the backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f419eb2",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "``` python\n",
    "raw = [\n",
    "  {ts:\"13:00\", pid:1, ask_px:100, ask_sz:50},\n",
    "  {ts:\"13:00\", pid:1, ask_px:101, ask_sz:45},\n",
    "  {ts:\"13:00\", pid:2, ask_px:102, ask_sz:40},\n",
    "  {ts:\"13:01\", pid:2, ask_px:103, ask_sz:30},\n",
    "  {ts:\"13:01\", pid:1, ask_px:101, ask_sz:75},\n",
    "]\n",
    "```\n",
    "This is an example raw message that the `l1_day.csv` will feed us. The dataset contains duplicates which will need to be preprocessed. First sort this by `ts_event` and thne deduplicate by keeping the first row. This will yield the best ask/bid in the data stream.\n",
    "\n",
    "``` python\n",
    "snapshots = [\n",
    "  {\n",
    "    ts: \"13:00\",\n",
    "    venues: [\n",
    "      {\"venue\":1, \"ask_px\":100, \"ask_sz\":50},\n",
    "      {\"venue\":2, \"ask_px\":102, \"ask_sz\":40}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    ts: \"13:01\",\n",
    "    venues: [\n",
    "      {\"venue\":1, \"ask_px\":101, \"ask_sz\":75},\n",
    "      {\"venue\":2, \"ask_px\":103, \"ask_sz\":30}\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "```\n",
    "The snapshots contain the timestamp of the best asks for each venue. A venue is a `publisher_id` in the `l1_data.csv`. Let say that we must split 200 shares in 100 share increments across the different potential buers. We must choose a split that minimizes cost.\n",
    "\n",
    "## Static Allocator\n",
    "\n",
    "This is where the static allocator comes. For two venue in the example (multiples of 100 for 200 shares):\n",
    "```python\n",
    "splits = [\n",
    "    [0,200],\n",
    "    [100,100],\n",
    "    [200,0]\n",
    "]\n",
    "```\n",
    "For each split ($[x_1,x_2]$) for venues $v_1$ and $v_2$, the cost is defined by the function:\n",
    "```python\n",
    "cost = ∑ ( xᵢ * ask_pxᵢ\n",
    "           + λ_over  * max(0, xᵢ − ask_szᵢ)\n",
    "           + λ_under * max(0, ask_szᵢ − xᵢ)\n",
    "           + θ_queue * (1/ask_szᵢ) )\n",
    "```\n",
    "The optimal split is $[200,0]$ which has the cheapest cost of 20,018.05\n",
    "\n",
    "\n",
    "## Backtest The Strategy\n",
    "\n",
    "A backtest loop is run on the the snapshots where:\n",
    "- initialize variables: `remaining_cash = 200, cash_spent = 0`\n",
    "- at snapshot \"13:00\":\n",
    "    - allocator send 200 to venue 1, 0 to venue 2\n",
    "    - venue 1 has 50 avaliable: fills 50 @ 100\n",
    "    - `remaining_cash=150`\n",
    "- at snapshot \"13:01\":\n",
    "    - allocator now splits 150: $[0,150], [100,50], [150,0]$\n",
    "    - venue 1 has 75 avaliable: fills 75 @ 101\n",
    "    - `remaining_cash=75`\n",
    "- continue until `remaining_cash=0` or data ends\n",
    "\n",
    "## Finding Best Parameter\n",
    "\n",
    "I will do a parametr search for the best parameters and pick the combination yielding minimum total `cash_spent`\n",
    "```python\n",
    "λ_over ∈ [0.01, 0.1, 1.0]\n",
    "λ_under ∈ [0.01, 0.1, 1.0]\n",
    "θ_queue ∈ [0, 10, 100]\n",
    "```\n",
    "\n",
    "## Three Baselines Comparison\n",
    "Using the same snapshots I will run the baselines of:\n",
    "1. best-ask: always hit the lowest price venue first\n",
    "2. 60s TWAP: break total order into equal sized slices and executes each slice at regular time intervals regardless of how much vol is trading for. For exmaple, to buy 1000 shares over 10 mins, you place 100 shares every minute\n",
    "3. VWAP: executes your roder in proportion to that market's avaliable liquidity meaning that you trade more when displayed volume is high and less when it's low\n",
    "\n",
    "*To aid understanding, this example shows what the code does or for reviewing*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1b0b670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"best_params\": {\n",
      "    \"lambda_over\": 1.246878665907564,\n",
      "    \"lambda_under\": 0.05695262671673521,\n",
      "    \"theta_queue\": 27.188902645221663\n",
      "  },\n",
      "  \"router\": {\n",
      "    \"total_spent\": 1114102.2800000003,\n",
      "    \"avg_price\": 222.82045600000006\n",
      "  },\n",
      "  \"best_ask\": {\n",
      "    \"total_spent\": 1114102.2800000003,\n",
      "    \"avg_price\": 222.82045600000006,\n",
      "    \"savings_bps\": 0.0\n",
      "  },\n",
      "  \"twap\": {\n",
      "    \"total_spent\": 1115427.5850538702,\n",
      "    \"avg_price\": 223.08551701077405,\n",
      "    \"savings_bps\": 11.881587577968627\n",
      "  },\n",
      "  \"vwap\": {\n",
      "    \"total_spent\": 1115320.7351223256,\n",
      "    \"avg_price\": 223.06414702446511,\n",
      "    \"savings_bps\": 10.924706086377022\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## hold quote information from single venue\n",
    "@dataclass(slots=True)\n",
    "class VenueLevel:\n",
    "    venue_id: int # id of venue\n",
    "    px: float     # price offered\n",
    "    sz: int       # size offered at price\n",
    "\n",
    "## snapshot holds venue quotes at a particular timestamp\n",
    "@dataclass(slots=True)\n",
    "class Snapshot:\n",
    "    ts: str # timestamp of the snapshot\n",
    "    venues: List[VenueLevel] # list of VenueLevel objects\n",
    "\n",
    "    @staticmethod\n",
    "    def from_group(ts: str, group: pd.DataFrame) -> \"Snapshot\":\n",
    "        return Snapshot(\n",
    "            ts,\n",
    "            [\n",
    "                VenueLevel(int(v), float(p), int(s))\n",
    "                for v, p, s in zip(\n",
    "                    group.publisher_id.values,\n",
    "                    group.ask_px_00.values,\n",
    "                    group.ask_sz_00.values,\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "\n",
    "## load the CSV and parse into snapshots sorted by timestamp \n",
    "def load_snapshots(csv_path: str | Path) -> List[Snapshot]:\n",
    "    csv_path = Path(csv_path)\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(csv_path)\n",
    "    df = (\n",
    "        pd.read_csv(csv_path)\n",
    "        .sort_values(\"ts_event\")\n",
    "        .drop_duplicates(subset=[\"ts_event\", \"publisher_id\"], keep=\"first\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return [Snapshot.from_group(ts, grp) for ts, grp in df.groupby(\"ts_event\", sort=True)]\n",
    "\n",
    "## Generate n tuple (in multiples of chunk) summing to total\n",
    "def enumerate_splits(total: int, n: int, *, chunk: int = 100) -> np.ndarray:\n",
    "    \"\"\"All non-negative n-tuples (multiples of *chunk*) summing to *total*.\"\"\"\n",
    "    levels = total // chunk + 1\n",
    "    grids = [np.arange(levels) * chunk for _ in range(n)]\n",
    "    mesh = np.array(np.meshgrid(*grids, indexing=\"ij\"))\n",
    "    combos = mesh.reshape(n, -1).T\n",
    "    return combos[combos.sum(axis=1) == total]\n",
    "\n",
    "## generate n-tiples for each split allocaiton across venues\n",
    "def compute_cost_matrix(\n",
    "    splits: np.ndarray,\n",
    "    venues: List[VenueLevel],\n",
    "    lambda_over: float,\n",
    "    lambda_under: float,\n",
    "    theta_queue: float,\n",
    ") -> np.ndarray:\n",
    "    if len(splits) == 0:\n",
    "        return np.empty(0)\n",
    "\n",
    "    px = np.fromiter((v.px for v in venues), float)\n",
    "    q = np.fromiter((v.sz for v in venues), float)\n",
    "\n",
    "    x = splits\n",
    "    exec_pay = (x * px).sum(axis=1)\n",
    "    over_pen = lambda_over * np.maximum(0, x - q).sum(axis=1)\n",
    "    under_pen = lambda_under * np.maximum(0, q - x).sum(axis=1)\n",
    "    queue_pen = theta_queue * (1 / np.where(q > 0, q, 1)).sum()\n",
    "    return exec_pay + over_pen + under_pen + queue_pen\n",
    "\n",
    "## main allocator: determine how much to send to each venue for a snapshot\n",
    "def allocate(\n",
    "    remaining: int,\n",
    "    venues: List[VenueLevel],\n",
    "    lambda_over: float,\n",
    "    lambda_under: float,\n",
    "    theta_queue: float,\n",
    "    *,\n",
    "    chunk: int = 100,\n",
    ") -> Dict[int, int]:\n",
    "    \"\"\"Return {venue_id: shares_to_send} for the current snapshot.\"\"\"\n",
    "    if remaining == 0 or len(venues) == 0:\n",
    "        return {}\n",
    "\n",
    "    splits = enumerate_splits(remaining, len(venues), chunk=chunk)\n",
    "\n",
    "    # retry with finest granularity if coarse grid produced nothing\n",
    "    if len(splits) == 0 and chunk != 1:\n",
    "        splits = enumerate_splits(remaining, len(venues), chunk=1)\n",
    "\n",
    "    # ultimate fall-back: hit the cheapest venue with everything\n",
    "    if len(splits) == 0:\n",
    "        best = min(venues, key=lambda v: v.px)\n",
    "        return {best.venue_id: remaining}\n",
    "\n",
    "    costs = compute_cost_matrix(splits, venues, lambda_over, lambda_under, theta_queue)\n",
    "    best_split = splits[costs.argmin()]\n",
    "    return {v.venue_id: int(x) for v, x in zip(venues, best_split)}\n",
    "\n",
    "# run the backtest with given parameters across all snapshots\n",
    "def run_backtest(\n",
    "    snapshots: List[Snapshot],\n",
    "    lambda_over: float,\n",
    "    lambda_under: float,\n",
    "    theta_queue: float,\n",
    "    *,\n",
    "    order_size: int = 5_000,\n",
    "    side: str = \"buy\",\n",
    "    chunk: int = 100,\n",
    ") -> Tuple[float, float, List[Tuple[str, float]]]:\n",
    "    sign = 1 if side == \"buy\" else -1\n",
    "    remaining, cash, filled = order_size, 0.0, 0\n",
    "    cumulative: List[Tuple[str, float]] = []\n",
    "\n",
    "    for snap in snapshots:\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "        alloc = allocate(\n",
    "            remaining, snap.venues,\n",
    "            lambda_over, lambda_under, theta_queue,\n",
    "            chunk=chunk,\n",
    "        )\n",
    "        for v in snap.venues:\n",
    "            send = alloc.get(v.venue_id, 0)\n",
    "            fill = min(send, v.sz)\n",
    "            cash += sign * fill * v.px\n",
    "            filled += fill\n",
    "        remaining = order_size - filled\n",
    "        cumulative.append((snap.ts, abs(cash)))\n",
    "    avg = abs(cash) / filled if filled else float(\"inf\")\n",
    "    return abs(cash), avg, cumulative\n",
    "\n",
    "# baseline strategy: always hit the best ask (lowest price)\n",
    "def best_ask_baseline(snaps: List[Snapshot], *, size=5_000):\n",
    "    remain, cash = size, 0.0\n",
    "    for s in snaps:\n",
    "        if remain <= 0:\n",
    "            break\n",
    "        v = min(s.venues, key=lambda v: v.px)\n",
    "        take = min(remain, v.sz)\n",
    "        cash += take * v.px\n",
    "        remain -= take\n",
    "    return cash, cash / size, None\n",
    "\n",
    "# vwap\n",
    "def vwap_baseline(snaps: List[Snapshot], *, size=5_000):\n",
    "    num = sum(v.px * v.sz for s in snaps for v in s.venues)\n",
    "    den = sum(v.sz for s in snaps for v in s.venues)\n",
    "    vwap = num / den\n",
    "    return vwap * size, vwap, None\n",
    "\n",
    "# twap\n",
    "def twap_baseline(snaps: List[Snapshot], *, size=5_000, bucket=60):\n",
    "    times = [datetime.fromisoformat(s.ts[:-1]) for s in snaps]\n",
    "    start = times[0]\n",
    "    buckets: Dict[int, List[Snapshot]] = {}\n",
    "    for t, s in zip(times, snaps):\n",
    "        idx = math.floor((t - start).total_seconds() / bucket)\n",
    "        buckets.setdefault(idx, []).append(s)\n",
    "    target = size / len(buckets)\n",
    "    cash = filled = 0.0\n",
    "    for grp in buckets.values():\n",
    "        pxs = [v.px for s in grp for v in s.venues]\n",
    "        cash += min(target, size - filled) * (sum(pxs) / len(pxs))\n",
    "        filled += target\n",
    "    return cash, cash / size, None\n",
    "\n",
    "# draws a random float uniformly\n",
    "def _logu(rng, lo, hi):\n",
    "    return 10 ** rng.uniform(math.log10(lo), math.log10(hi))\n",
    "\n",
    "# search for the best parameter using randomized trials\n",
    "def search_parameters(snaps: List[Snapshot], *, trials=120, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    best = {\"cost\": float(\"inf\")}\n",
    "    for _ in range(trials):\n",
    "        lo = _logu(rng, 1e-3, 10)\n",
    "        lu = _logu(rng, 1e-3, 10)\n",
    "        th = _logu(rng, 1e-2, 1e2)\n",
    "        cost, avg, _ = run_backtest(snaps, lo, lu, th)\n",
    "        if cost < best[\"cost\"]:\n",
    "            best = {\n",
    "                \"cost\": cost,\n",
    "                \"avg\": avg,\n",
    "                \"lambda_over\": lo,\n",
    "                \"lambda_under\": lu,\n",
    "                \"theta_queue\": th,\n",
    "            }\n",
    "    return best\n",
    "\n",
    "# Calculate basis points improvement\n",
    "def _bps(router_cost, base_cost):\n",
    "    return (base_cost - router_cost) / base_cost * 1e4\n",
    "\n",
    "# Full evaluation of router vs. baselines\n",
    "def run_full_backtest(csv: str | Path = \"l1_day.csv\", *, trials: int = 120):\n",
    "    \"\"\"High-level helper: returns the full result dict (no printing).\"\"\"\n",
    "    snaps = load_snapshots(csv)\n",
    "    best = search_parameters(snaps, trials=trials)\n",
    "\n",
    "    rc, ra, _ = run_backtest(\n",
    "        snaps, best[\"lambda_over\"], best[\"lambda_under\"], best[\"theta_queue\"]\n",
    "    )\n",
    "    bc, ba, _ = best_ask_baseline(snaps)\n",
    "    tc, ta, _ = twap_baseline(snaps)\n",
    "    vc, va, _ = vwap_baseline(snaps)\n",
    "\n",
    "    return {\n",
    "        \"best_params\": {\n",
    "            k: best[k] for k in (\"lambda_over\", \"lambda_under\", \"theta_queue\")\n",
    "        },\n",
    "        \"router\": {\"total_spent\": rc, \"avg_price\": ra},\n",
    "        \"best_ask\": {\n",
    "            \"total_spent\": bc,\n",
    "            \"avg_price\": ba,\n",
    "            \"savings_bps\": _bps(rc, bc),\n",
    "        },\n",
    "        \"twap\": {\n",
    "            \"total_spent\": tc,\n",
    "            \"avg_price\": ta,\n",
    "            \"savings_bps\": _bps(rc, tc),\n",
    "        },\n",
    "        \"vwap\": {\n",
    "            \"total_spent\": vc,\n",
    "            \"avg_price\": va,\n",
    "            \"savings_bps\": _bps(rc, vc),\n",
    "        },\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    res = run_full_backtest()\n",
    "    print(json.dumps(res, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
